{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wuwenjie1992/RenRenVerificationCode/blob/master/nb/Qwen2.5_(3B)-GRPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsGZSa68jK2w"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ë¶ÅËøêË°åÊ≠§ÂäüËÉΩÔºåËØ∑Âú®**ÂÖçË¥π** Tesla T4 Google Colab ÂÆû‰æã‰∏äÊåâ‚Äú*ËøêË°åÊó∂*‚ÄùÂπ∂Êåâ‚Äú*ÂÖ®ÈÉ®ËøêË°å*‚ÄùÔºÅ\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Â¶ÇÊûúÊÇ®ÈúÄË¶ÅÂ∏ÆÂä©ÔºåËØ∑Âä†ÂÖ• Discord + ‚≠ê <i>Âú® <a ‰∏ä‰∏∫Êàë‰ª¨ÁÇπËµûhref=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "Ë¶ÅÂú®ÊÇ®Ëá™Â∑±ÁöÑËÆ°ÁÆóÊú∫‰∏äÂÆâË£Ö UnslothÔºåËØ∑ÊåâÁÖßÊàë‰ª¨ Github È°µÈù¢‰∏äÁöÑÂÆâË£ÖËØ¥ÊòéËøõË°åÊìç‰Ωú[Ê≠§Â§Ñ](https://docs.unsloth.ai/get-started/installing-+-updating)„ÄÇ\n",
        "\n",
        "ÊÇ®Â∞ÜÂ≠¶‰π†Â¶Ç‰ΩïËøõË°å[Êï∞ÊçÆÂáÜÂ§á](#Data)„ÄÅÂ¶Ç‰Ωï[ËÆ≠ÁªÉ](#Train)„ÄÅÂ¶Ç‰Ωï[ËøêË°åÊ®°Âûã](#Inference) Âíå[Â¶Ç‰Ωï‰øùÂ≠ò](#Save)\n",
        "\n",
        "ËÆøÈóÆÊàë‰ª¨ÁöÑÊñáÊ°£Ôºå‰∫ÜËß£Êàë‰ª¨ÊâÄÊúâÁöÑ[Ê®°Âûã‰∏ä‰º†](https://docs.unsloth.ai/get-started/all-our-models) Âíå[Á¨îËÆ∞Êú¨](https://docs.unsloth.ai/get-started/unsloth-notebooks)„ÄÇ"
      ],
      "metadata": {
        "id": "6QDr6dt_2CIX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ME8zKIqjK2y"
      },
      "source": [
        "### News\n",
        "### Êñ∞Èóª"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYRc2rzrjK2y"
      },
      "source": [
        "**Read our [blog post](https://unsloth.ai/blog/r1-reasoning) for guidance to train reasoning model.** GRPO notebook is inspired by [@shxf0072](https://x.com/shxf0072/status/1886085377146180091), [@Teknium1](https://x.com/Teknium1/status/1885077369142337550), [@willccbb](https://gist.github.com/willccbb/4676755236bb08cab5f4e54a0475d6fb)\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n",
        "\n",
        "**ÈòÖËØªÊàë‰ª¨ÁöÑ [ÂçöÂÆ¢ÊñáÁ´†](https://unsloth.ai/blog/r1-reasoning)ÔºåËé∑ÂèñËÆ≠ÁªÉÊé®ÁêÜÊ®°ÂûãÁöÑÊåáÂØº„ÄÇ** GRPO Á¨îËÆ∞Êú¨ÁöÑÁÅµÊÑüÊù•Ëá™ [@shxf0072](https://x.com/shxf0072/status/1886085377146180091)„ÄÅ[@Teknium1](https://x.com/Teknium1/status/1885077369142337550)„ÄÅ[@willccbb](https://gist.github.com/willccbb/4676755236bb08cab5f4e54a0475d6fb)\n",
        "\n",
        "ËÆøÈóÆÊàë‰ª¨ÁöÑÊñáÊ°£Ôºå‰∫ÜËß£Êàë‰ª¨ÊâÄÊúâÁöÑ [Ê®°Âûã‰∏ä‰º†](https://docs.unsloth.ai/get-started/all-our-models) Âíå[Á¨îËÆ∞Êú¨]Ôºàhttps://docs.unsloth.ai/get-started/unsloth-notebooksÔºâ„ÄÇ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaAX8GvfjK2z"
      },
      "source": [
        "### Installation ÂÆâË£Ö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vl3GEtNpjK20"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Ë∑≥Ëøá Colab ‰∏≠ÁöÑÈáçÂêØÊ∂àÊÅØ Skip restarting message in Colab\n",
        "import sys; modules = list(sys.modules.keys())\n",
        "for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
        "\n",
        "!pip install unsloth vllm\n",
        "!pip install --upgrade pillow\n",
        "# If you are running this notebook on local, you need to install `diffusers` too\n",
        "# Â¶ÇÊûú‰Ω†Âú®Êú¨Âú∞ËøêË°åÊ≠§Á¨îËÆ∞Êú¨Ôºå‰Ω†ËøòÈúÄË¶ÅÂÆâË£Ö‚Äúdiffusers‚Äù\n",
        "# !pip install diffusers\n",
        "# Temporarily install a specific TRL nightly version ‰∏¥Êó∂ÂÆâË£ÖÁâπÂÆöÁöÑ TRL Â§úÈó¥ÁâàÊú¨\n",
        "!pip install git+https://github.com/huggingface/trl.git@e95f9fb74a3c3647b86f251b7e230ec51c64b72b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yxxDaVXjK21"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1cRtXR2yknS"
      },
      "source": [
        "Use `PatchFastRL` before all functions to patch GRPO and other RL algorithms! Âú®ÊâÄÊúâÂáΩÊï∞‰πãÂâç‰ΩøÁî®`PatchFastRL`Êù•‰øÆË°• GRPO ÂíåÂÖ∂‰ªñ RL ÁÆóÊ≥ïÔºÅ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59DIs5BMcvjN",
        "outputId": "ee7c1946-c4f9-4bae-dd09-f5d067b54f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Patching Xformers to fix some performance issues.\n",
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel, PatchFastRL\n",
        "PatchFastRL(\"GRPO\", FastLanguageModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Joje4qPsyxM9"
      },
      "source": [
        "Load up `Qwen 2.5 3B Instruct`, and set parameters Âä†ËΩΩ`Qwen 2.5 3B Instruct`ÔºåÂπ∂ËÆæÁΩÆÂèÇÊï∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkIvEkIIkEyB"
      },
      "outputs": [],
      "source": [
        "from unsloth import is_bfloat16_supported\n",
        "import torch\n",
        "max_seq_length = 1024 # ÂèØ‰ª•Â¢ûÂä†Êõ¥ÈïøÁöÑÊé®ÁêÜËΩ®Ëøπ Can increase for longer reasoning traces\n",
        "lora_rank = 8 # Á≠âÁ∫ßË∂äÈ´ò = Ë∂äËÅ™ÊòéÔºå‰ΩÜÈÄüÂ∫¶Ë∂äÊÖ¢ Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = True, # False for LoRA 16bit\n",
        "    fast_inference = True, # ÂêØÁî® vLLM Âø´ÈÄüÊé®ÁêÜ Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.5, # Â¶ÇÊûúÂÜÖÂ≠ò‰∏çË∂≥ÂàôÂáèÂ∞ë Reduce if out of memory\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ], # Remove QKVO if out of memory\n",
        "    lora_alpha = lora_rank,\n",
        "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
        "    random_state = 3407,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y56ln_izS9E"
      },
      "source": [
        "### Data Prep\n",
        "<a name=\"Data\"></a>\n",
        "\n",
        "We directly leverage [@willccbb](https://gist.github.com/willccbb/4676755236bb08cab5f4e54a0475d6fb) for data prep and all reward functions. You are free to create your own!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXk993X6C2ZZ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Load and prep dataset\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "...\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "XML_COT_FORMAT = \"\"\"\\\n",
        "<reasoning>\n",
        "{reasoning}\n",
        "</reasoning>\n",
        "<answer>\n",
        "{answer}\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    answer = text.split(\"<answer>\")[-1]\n",
        "    answer = answer.split(\"</answer>\")[0]\n",
        "    return answer.strip()\n",
        "\n",
        "def extract_hash_answer(text: str) -> str | None:\n",
        "    if \"####\" not in text:\n",
        "        return None\n",
        "    return text.split(\"####\")[1].strip()\n",
        "\n",
        "# uncomment middle messages for 1-shot prompting\n",
        "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
        "    data = load_dataset('openai/gsm8k', 'main')[split] # type: ignore\n",
        "    data = data.map(lambda x: { # type: ignore\n",
        "        'prompt': [\n",
        "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "            {'role': 'user', 'content': x['question']}\n",
        "        ],\n",
        "        'answer': extract_hash_answer(x['answer'])\n",
        "    }) # type: ignore\n",
        "    return data # type: ignore\n",
        "\n",
        "dataset = get_gsm8k_questions()\n",
        "\n",
        "# Reward functions\n",
        "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    q = prompts[0][-1]['content']\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
        "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
        "\n",
        "def int_reward_func(completions, **kwargs) -> list[float]:\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
        "\n",
        "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def count_xml(text) -> float:\n",
        "    count = 0.0\n",
        "    if text.count(\"<reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n<answer>\\n\") == 1:\n",
        "        count += 0.125\n",
        "        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n",
        "    if text.count(\"\\n</answer>\") == 1:\n",
        "        count += 0.125\n",
        "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n",
        "    return count\n",
        "\n",
        "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
        "    contents = [completion[0][\"content\"] for completion in completions]\n",
        "    return [count_xml(c) for c in contents]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTnL_tJnzh2L"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "\n",
        "Now set up GRPO Trainer and all configurations!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptqkXK2D4d6p"
      },
      "outputs": [],
      "source": [
        "from trl import GRPOConfig, GRPOTrainer\n",
        "training_args = GRPOConfig(\n",
        "    use_vllm = True, # use vLLM for fast inference!\n",
        "    learning_rate = 5e-6,\n",
        "    adam_beta1 = 0.9,\n",
        "    adam_beta2 = 0.99,\n",
        "    weight_decay = 0.1,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"cosine\",\n",
        "    optim = \"adamw_8bit\",\n",
        "    logging_steps = 1,\n",
        "    bf16 = is_bfloat16_supported(),\n",
        "    fp16 = not is_bfloat16_supported(),\n",
        "    per_device_train_batch_size = 1,\n",
        "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
        "    num_generations = 4, # Decrease if out of memory\n",
        "    max_prompt_length = 256,\n",
        "    max_completion_length = 200,\n",
        "    num_train_epochs = 1, # Set to 1 for a full training run\n",
        "    # max_steps = 250,\n",
        "    save_steps = 250,\n",
        "    max_grad_norm = 0.1,\n",
        "    report_to = \"none\", # Can use Weights & Biases\n",
        "    output_dir = \"outputs\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_71Y0eKz5yE"
      },
      "source": [
        "And let's run the trainer! If you scroll up, you'll see a table of rewards. The goal is to see the `reward` column increase!\n",
        "\n",
        "You might have to wait 150 to 200 steps for any action. You'll probably get 0 reward for the first 100 steps. Please be patient!\n",
        "\n",
        "| Step | Training Loss | reward    | reward_std | completion_length | kl       |\n",
        "|------|---------------|-----------|------------|-------------------|----------|\n",
        "| 1    | 0.000000      | 0.125000  | 0.000000   | 200.000000        | 0.000000 |\n",
        "| 2    | 0.000000      | 0.072375  | 0.248112   | 200.000000        | 0.000000 |\n",
        "| 3    | 0.000000      | -0.079000 | 0.163776   | 182.500000        | 0.000005 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzOuSVCL_GA9"
      },
      "outputs": [],
      "source": [
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = [\n",
        "        xmlcount_reward_func,\n",
        "        soft_format_reward_func,\n",
        "        strict_format_reward_func,\n",
        "        int_reward_func,\n",
        "        correctness_reward_func,\n",
        "    ],\n",
        "    args = training_args,\n",
        "    train_dataset = dataset,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUbluAAhD0Lg"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Now let's try the model we just trained! First, let's first try the model without any GRPO trained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "IqzsdZzeDM_m",
        "outputId": "83cfc6c3-215f-4e42-d764-26fb21a5debb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.47it/s, est. speed input: 55.04 toks/s, output: 28.26 toks/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In the word \"strawberry,\" there is one occurrence of the letter \"r.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"user\", \"content\" : \"How many r's are in strawberry?\"},\n",
        "], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.8,\n",
        "    top_p = 0.95,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    [text],\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = None,\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CyeincBQoIUx",
        "outputId": "9832dab7-6f24-406b-e80f-aefd450f0531",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'token': '<|im_start|>', 'logprob': -0.16539204120635986}, {'token': 'system', 'logprob': -0.006927993148565292}, {'token': 'ƒä', 'logprob': -0.6365760564804077}, {'token': 'You', 'logprob': -0.7447315454483032}, {'token': 'ƒ†are', 'logprob': -0.3050098121166229}, {'token': 'ƒ†Q', 'logprob': -0.0003251500893384218}, {'token': 'wen', 'logprob': -9.536738616588991e-07}, {'token': ',', 'logprob': -2.264974000354414e-06}, {'token': 'ƒ†created', 'logprob': -2.3841830625315197e-06}, {'token': 'ƒ†by', 'logprob': -1.1205610462639015e-05}, {'token': 'ƒ†Alibaba', 'logprob': -0.0010255083907395601}, {'token': 'ƒ†Cloud', 'logprob': -0.00023934361524879932}, {'token': '.', 'logprob': -9.536738616588991e-07}, {'token': 'ƒ†You', 'logprob': -3.576278118089249e-07}, {'token': 'ƒ†are', 'logprob': -0.34255820512771606}, {'token': 'ƒ†a', 'logprob': -0.06740865856409073}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(input_ids=input_ids).logits[:, :-1, :].shape"
      ],
      "metadata": {
        "id": "CQSK94F7nonq",
        "outputId": "d7af3faf-6bcc-4df1-d2de-7e2a5c72297f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 36, 151936])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(input_ids=input_ids).logits"
      ],
      "metadata": {
        "id": "Mi2KegBDnozz",
        "outputId": "88934b4f-e7d0-44ff-9bef-75dd5a1097e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 6.3984,  6.9062,  4.9336,  ..., -2.7051, -2.7051, -2.7051],\n",
              "         [ 6.3242,  5.7383,  6.2734,  ..., -0.7817, -0.7817, -0.7817],\n",
              "         [ 6.6328,  9.5547, 11.7500,  ..., -4.1602, -4.1602, -4.1602],\n",
              "         ...,\n",
              "         [-2.1953,  7.9453, -6.1133,  ...,  4.8398,  4.8398,  4.8398],\n",
              "         [ 1.1201,  0.8633,  4.2891,  ..., -0.3706, -0.3706, -0.3706],\n",
              "         [ 7.9609, 17.2812,  7.1719,  ..., -3.5547, -3.5547, -3.5547]]],\n",
              "       device='cuda:0', dtype=torch.float16, grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xzw0at5ono4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3VBYm0Fno8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4lzJD7REFjs"
      },
      "source": [
        "And now with the LoRA we just trained with GRPO - we first save the LoRA first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YC9BBT0RESln"
      },
      "outputs": [],
      "source": [
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LherO2vzEbMt"
      },
      "source": [
        "Now we load the LoRA and test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "SDKIhhvN6lAF",
        "outputId": "8bc37894-678f-40d7-874b-365300685836"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.06s/it, est. speed input: 14.05 toks/s, output: 29.09 toks/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<reasoning>\\nTo find out how many times the letter \\'r\\' appears in the word \"strawberry\", we can go through the word character by character and count each occurrence of \\'r\\'. In \"strawberry\", the letter \\'r\\' appears 3 times: once in the beginning, once in the middle, and once at the end of the word.\\n</reasoning>\\n<answer>\\n3\\n</answer>'"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"system\", \"content\" : SYSTEM_PROMPT},\n",
        "    {\"role\" : \"user\", \"content\" : \"How many r's are in strawberry?\"},\n",
        "], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.8,\n",
        "    top_p = 0.95,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    text,\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = model.load_lora(\"grpo_saved_lora\"),\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZBnvg2f9Nlg"
      },
      "source": [
        "Our reasoning model is much better - it's not always correct, since we only trained it for an hour or so - it'll be better if we extend the sequence length and train for longer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RphEZRSfFhru"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwNY9_PrFiXZ"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDUGPiL3Fkkq"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGo4dbWvFk4M"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcYNnwXljK2_"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Llama 3.2 Conversational notebook. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}